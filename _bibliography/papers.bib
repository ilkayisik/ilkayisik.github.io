@article{Vessel2019,
abstract = {Visual aesthetic evaluations, which impact decision-making and well-being, recruit the ventral visual pathway, subcortical reward circuitry, and parts of the medial prefrontal cortex overlapping with the default-mode network (DMN). However, it is unknown whether these networks represent aesthetic appeal in a domain-general fashion, independent of domain-specific representations of stimulus content (artworks versus architecture or natural landscapes). Using a classification approach, we tested whether the DMN or ventral occipitotemporal cortex (VOT) contains a domain-general representation of aesthetic appeal. Classifiers were trained on multivoxel functional MRI response patterns collected while observers made aesthetic judgments about images from one aesthetic domain. Classifier performance (high vs. low aesthetic appeal) was then tested on response patterns from held-out trials from the same domain to derive a measure of domain-specific coding, or from a different domain to derive a measure of domain-general coding. Activity patterns in category-selective VOT contained a degree of domain-specific information about aesthetic appeal, but did not generalize across domains. Activity patterns from the DMN, however, were predictive of aesthetic appeal across domains. Importantly, the ability to predict aesthetic appeal varied systematically; predictions were better for observers who gave more extreme ratings to images subsequently labeled as “high” or “low.” These findings support a model of aesthetic appreciation whereby domain-specific representations of the content of visual experiences in VOT feed in to a “core” domain-general representation of visual aesthetic appeal in the DMN. Whole-brain “searchlight” analyses identified additional prefrontal regions containing information relevant for appreciation of cultural artifacts (artwork and architecture) but not landscapes.},
author = {Vessel, Edward A and Isik, Ayse Ilkay and Belfi, Amy M and Stahl, Jonathan L and Starr, G Gabrielle},
doi = {10.1073/pnas.1902650116},
file = {:Users/ilkayisik/Documents/Mendeley Desktop//Vessel et al. - 2019 - The default-mode network represents aesthetic appeal that generalizes across visual domains.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {+a,MVPA,fmri,neuroaesthetics,visual},
mendeley-tags = {+a,MVPA,fmri,neuroaesthetics,visual},
month = {sep},
number = {38},
pages = {19155--19164},
title = {{The default-mode network represents aesthetic appeal that generalizes across visual domains}},
url = {http://www.pnas.org/content/early/2019/09/03/1902650116.abstract http://www.pnas.org/lookup/doi/10.1073/pnas.1902650116},
volume = {116},
year = {2019}
}
@article{Esteban2018,
abstract = {Preprocessing of functional MRI (fMRI) involves numerous steps to clean and standardize data before statistical analysis. Generally, researchers create ad hoc preprocessing workflows for each new dataset, building upon a large inventory of tools available for each step. The complexity of these workflows has snowballed with rapid advances in MR data acquisition and image processing techniques. We introduce fMRIPrep, an analysis-agnostic tool that addresses the challenge of robust and reproducible preprocessing for task-based and resting fMRI data. FMRIPrep automatically adapts a best-in-breed workflow to the idiosyncrasies of virtually any dataset, ensuring high-quality preprocessing with no manual intervention. By introducing visual assessment checkpoints into an iterative integration framework for software-testing, we show that fMRIPrep robustly produces high-quality results on a diverse fMRI data collection comprising participants from 54 different studies in the OpenfMRI repository. We review the distinctive features of fMRIPrep in a qualitative comparison to other preprocessing workflows. We demonstrate that fMRIPrep achieves higher spatial accuracy as it introduces less uncontrolled spatial smoothness than one commonly used preprocessing tool. FMRIPrep has the potential to transform fMRI research by equipping neuroscientists with a high-quality, robust, easy-to-use and transparent preprocessing workflow which can help ensure the validity of inference and the interpretability of their results.},
author = {Esteban, Oscar and Markiewicz, Christopher J and Blair, Ross W and Moodie, Craig A and Isik, Ayse Ilkay and Erramuzpe, Asier and Kent, James D and Goncalves, Mathias and DuPre, Elizabeth and Snyder, Madeleine and Oya, Hiroyuki and Ghosh, Satrajit S and Wright, Jessey and Durnez, Joke and Poldrack, Russell A and Gorgolewski, Krzysztof J},
doi = {10.1038/s41592-018-0235-4},
file = {:Users/ilkayisik/Documents/Mendeley Desktop/Esteban et al. - 2018 - fMRIPrep a robust preprocessing pipeline for functional MRI.pdf:pdf},
issn = {1548-7091},
journal = {Nature Methods},
month = {dec},
pages = {1--20},
publisher = {Springer US},
title = {{fMRIPrep: a robust preprocessing pipeline for functional MRI}},
url = {http://biorxiv.org/content/early/2018/04/25/306951.abstract http://www.nature.com/articles/s41592-018-0235-4},
year = {2018}
}
@article{Isik2017,
abstract = {{\textcopyright} 2017 The Authors In the later stages of addiction, automatized processes play a prominent role in guiding drug-seeking and drug-taking behavior. However, little is known about the neural correlates of automatized drug-taking skills and drug-related action knowledge in humans. We employed functional magnetic resonance imaging (fMRI) while smokers and non-smokers performed an orientation affordance task, where compatibility between the hand used for a behavioral response and the spatial orientation of a priming stimulus leads to shorter reaction times resulting from activation of the corresponding motor representations. While non-smokers exhibited this behavioral effect only for control objects, smokers showed the affordance effect for both control and smoking-related objects. Furthermore, smokers exhibited reduced fMRI activation for smoking-related as compared to control objects for compatible stimulus-response pairings in a sensorimotor brain network consisting of the right primary motor cortex, supplementary motor area, middle occipital gyrus, left fusiform gyrus and bilateral cingulate gyrus. In the incompatible condition, we found higher fMRI activation in smokers for smoking-related as compared to control objects in the right primary motor cortex, cingulate gyrus, and left fusiform gyrus. This suggests that the activation and performance of deeply embedded, automatized drug-taking schemata employ less brain resources. This might reduce the threshold for relapsing in individuals trying to abstain from smoking. In contrast, the interruption or modification of already triggered automatized action representations require increased neural resources.},
author = {Isik, Ayse Ilkay and Naumer, Marcus J. and Kaiser, Jochen and Buschenlange, Christian and Wiesmann, Sandro and Czoschke, Stefan and Yalachkov, Yavor},
doi = {10.1016/j.nicl.2017.06.021},
file = {:Users/ilkayisik/Documents/Mendeley Desktop//Isik et al. - 2017 - Automatized smoking-related action schemata are reflected by reduced fMRI activity in sensorimotor brain regions of.pdf:pdf},
issn = {22131582},
journal = {NeuroImage: Clinical},
pages = {753--760},
title = {{Automatized smoking-related action schemata are reflected by reduced fMRI activity in sensorimotor brain regions of smokers}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S2213158217301523},
volume = {15},
year = {2017}
}
@article{Belfi2019,
abstract = {Neuroaesthetics is a rapidly developing interdisciplinary field of research that aims to understand the neural substrates of aesthetic experience: While understanding aesthetic experience has been an objective of philosophers for centuries, it has only more recently been embraced by neuroscientists. Recent work in neuroaesthetics has revealed that aesthetic experience with static visual art engages visual, reward and default-mode networks. Very little is known about the temporal dynamics of these networks during aesthetic appreciation. Previous behavioral and brain imaging research suggests that critical aspects of aesthetic experience have slow dynamics, taking more than a few seconds, making them amenable to study with fMRI. Here, we identified key aspects of the dynamics of aesthetic experience while viewing art for various durations. In the first few seconds following image onset, activity in the DMN (and high-level visual and reward regions) was greater for very pleasing images; in the DMN this activity counteracted a suppressive effect that grew longer and deeper with increasing image duration. In addition, for very pleasing art, the DMN response returned to baseline in a manner time-locked to image offset. Conversely, for non-pleasing art, the timing of this return to baseline was inconsistent. This differential response in the DMN may therefore reflect the internal dynamics of the participant's state: The participant disengages from art-related processing and returns to stimulus-independent thought. These dynamics suggest that the DMN tracks the internal state of a participant during aesthetic experience.},
author = {Belfi, Amy M and Vessel, Edward A and Brielmann, Aenne A and Isik, Ayse Ilkay and Chatterjee, Anjan and Leder, Helmut and Pelli, Denis G and Starr, G Gabrielle},
doi = {10.1016/j.neuroimage.2018.12.017},
file = {:Users/ilkayisik/Documents/Mendeley Desktop//Belfi et al. - 2019 - Dynamics of aesthetic experience are reflected in the default-mode network.pdf:pdf},
issn = {10538119},
journal = {NeuroImage},
keywords = {DMN,aesthetics,continuous judgment,fmri,visual},
mendeley-tags = {DMN,aesthetics,continuous judgment,fmri,visual},
month = {mar},
pages = {584--597},
title = {{Dynamics of aesthetic experience are reflected in the default-mode network}},
url = {https://www.sciencedirect.com/science/article/pii/S105381191832161X?dgcid=rss{\_}sd{\_}all https://linkinghub.elsevier.com/retrieve/pii/S105381191832161X},
volume = {188},
year = {2019}
}
@article{Botvinik-Nezer2020b,
author = {Botvinik-Nezer, Rotem and Holzmeister, Felix and Camerer, Colin F and Dreber, Anna and Huber, Juergen and Johannesson, Magnus and Kirchler, Michael and Iwanir, Roni and Mumford, Jeanette A. and Adcock, R Alison and Avesani, Paolo and Baczkowski, Blazej M and Bajracharya, Aahana and Bakst, Leah and Ball, Sheryl and Barilari, Marco and Bault, Nad{\`{e}}ge and Beaton, Derek and Beitner, Julia and Benoit, Roland G and Berkers, Ruud M W J and Bhanji, Jamil P and Biswal, Bharat B and Bobadilla-Suarez, Sebastian and Bortolini, Tiago and Bottenhorn, Katherine L and Bowring, Alexander and Braem, Senne and Brooks, Hayley R and Brudner, Emily G and Calderon, Cristian B. and Camilleri, Julia A and Castrellon, Jaime J and Cecchetti, Luca and Cieslik, Edna C and Cole, Zachary J and Collignon, Olivier and Cox, Robert W and Cunningham, William A. and Czoschke, Stefan and Dadi, Kamalaker and Davis, Charles P and Luca, Alberto De and Delgado, Mauricio R and Demetriou, Lysia and Dennison, Jeffrey B. and Di, Xin and Dickie, Erin W and Dobryakova, Ekaterina and Donnat, Claire L and Dukart, Juergen and Duncan, Niall W and Durnez, Joke and Eed, Amr and Eickhoff, Simon B. and Erhart, Andrew and Fontanesi, Laura and Fricke, G Matthew and Fu, Shiguang and Galv{\'{a}}n, Adriana and Gau, Remi and Genon, Sarah and Glatard, Tristan and Glerean, Enrico and Goeman, Jelle J and Golowin, Sergej A E and Gonz{\'{a}}lez-Garc{\'{i}}a, Carlos and Gorgolewski, Krzysztof J and Grady, Cheryl L and Green, Mikella A and {Guassi Moreira}, Jo{\~{a}}o F. and Guest, Olivia and Hakimi, Shabnam and Hamilton, J Paul and Hancock, Roeland and Handjaras, Giacomo and Harry, Bronson B and Hawco, Colin and Herholz, Peer and Herman, Gabrielle and Heunis, Stephan and Hoffstaedter, Felix and Hogeveen, Jeremy and Holmes, Susan and Hu, Chuan-peng and Huettel, Scott A and Hughes, Matthew E and Iacovella, Vittorio and Iordan, Alexandru D and Isager, Peder M and Isik, Ayse Ilkay and Jahn, Andrew and Johnson, Matthew R and Johnstone, Tom and Joseph, Michael J E and Juliano, Anthony C and Kable, Joseph W and Kassinopoulos, Michalis and Koba, Cemal and Kong, Xiang-zhen and Koscik, Timothy R and Kucukboyaci, Nuri Erkut and Kuhl, Brice A and Kupek, Sebastian and Laird, Angela R and Lamm, Claus and Langner, Robert and Lauharatanahirun, Nina and Lee, Hongmi and Lee, Sangil and Leemans, Alexander and Leo, Andrea and Lesage, Elise and Li, Flora and Li, Monica Y C and Lim, Phui Cheng and Lintz, Evan N and Liphardt, Schuyler W and {Losecaat Vermeer}, Annabel B. and Love, Bradley C and Mack, Michael L and Malpica, Norberto and Marins, Theo and Maumet, Camille and McDonald, Kelsey and McGuire, Joseph T. and Melero, Helena and {M{\'{e}}ndez Leal}, Adriana S. and Meyer, Benjamin and Meyer, Kristin N. and Mihai, Glad and Mitsis, Georgios D. and Moll, Jorge and Nielson, Dylan M. and Nilsonne, Gustav and Notter, Michael P and Olivetti, Emanuele and Onicas, Adrian I and Papale, Paolo and Patil, Kaustubh R and Peelle, Jonathan E and P{\'{e}}rez, Alexandre and Pischedda, Doris and Poline, Jean-Baptiste and Prystauka, Yanina and Ray, Shruti and Reuter-Lorenz, Patricia A. and Reynolds, Richard C. and Ricciardi, Emiliano and Rieck, Jenny R. and Rodriguez-Thompson, Anais M. and Romyn, Anthony and Salo, Taylor and Samanez-Larkin, Gregory R. and Sanz-Morales, Emilio and Schlichting, Margaret L. and Schultz, Douglas H. and Shen, Qiang and Sheridan, Margaret A. and Silvers, Jennifer A. and Skagerlund, Kenny and Smith, Alec and Smith, David V. and Sokol-Hessner, Peter and Steinkamp, Simon R and Tashjian, Sarah M and Thirion, Bertrand and Thorp, John N and Tingh{\"{o}}g, Gustav and Tisdall, Loreen and Tompson, Steven H and Toro-Serey, Claudio and {Torre Tresols}, Juan Jesus and Tozzi, Leonardo and Truong, Vuong and Turella, Luca and {van ‘t Veer}, Anna E. and Verguts, Tom and Vettel, Jean M. and Vijayarajah, Sagana and Vo, Khoi and Wall, Matthew B. and Weeda, Wouter D. and Weis, Susanne and White, David J. and Wisniewski, David and Xifra-Porxas, Alba and Yearling, Emily A. and Yoon, Sangsuk and Yuan, Rui and Yuen, Kenneth S. L. and Zhang, Lei and Zhang, Xu and Zosky, Joshua E. and Nichols, Thomas E. and Poldrack, Russell A. and Schonberg, Tom},
doi = {10.1038/s41586-020-2314-9},
file = {:Users/ilkayisik/Documents/Mendeley Desktop/Botvinik-Nezer et al. - 2020 - Variability in the analysis of a single neuroimaging dataset by many teams{\_}supl.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {supplemental information},
mendeley-tags = {supplemental information},
month = {may},
title = {{Variability in the analysis of a single neuroimaging dataset by many teams{\_}supl}},
url = {http://www.nature.com/articles/s41586-020-2314-9},
year = {2020}
}
@article{Isik2021,
abstract = {During aesthetically appealing visual experiences, visual content provides a basis for computation of affectively tinged representations of aesthetic value. How this happens in the brain is largely unexplored. Using engaging video clips of natural landscapes, we tested whether cortical regions that respond to perceptual aspects of an environment (e.g., spatial layout, object content and motion) were directly modulated by rated aesthetic appeal. Twenty-four participants watched a series of videos of natural landscapes while being scanned using functional magnetic resonance imaging (fMRI) and reported both continuous ratings of enjoyment (during the videos) and overall aesthetic judgments (after each video). Although landscape videos engaged a greater expanse of high-level visual cortex compared to that observed for images of landscapes, independently localized category-selective visual regions (e.g., scene-selective parahippocampal place area and motion-selective hMT+) were not significantly modulated by aesthetic appeal. Rather, a whole-brain analysis revealed modulations by aesthetic appeal in ventral (collateral sulcus) and lateral (middle occipital sulcus, posterior middle temporal gyrus) clusters that were adjacent to scene and motion selective regions. These findings suggest that aesthetic appeal per se is not represented in well-characterized feature- and category-selective regions of visual cortex. Rather, we propose that the observed activations reflect a local transformation from a feature-based visual representation to a representation of “elemental affect,” computed through information-processing mechanisms that detect deviations from an observer's expectations. Furthermore, we found modulation by aesthetic appeal in subcortical reward structures but not in regions of the default-mode network (DMN) nor orbitofrontal cortex, and only weak evidence for associated changes in functional connectivity. In contrast to other visual aesthetic domains, aesthetically appealing interactions with natural landscapes may rely more heavily on comparisons between ongoing stimulation and well-formed representations of the natural world, and less on top-down processes for resolving ambiguities or assessing self-relevance.},
author = {Isik, Ayse Ilkay and Vessel, Edward A},
doi = {10.3389/fnhum.2021.676032},
file = {:Users/ilkayisik/Documents/Mendeley Desktop/Isik, Vessel - 2021 - From Visual Perception to Aesthetic Appeal Brain Responses to Aesthetically Appealing Natural Landscape Movies.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {aesthetic appeal,aesthetics,elemental affect,fMRI, neuroaesthetics, naturalistic stimuli, lands,fmri,frontiers in human neuroscience,frontiersin,lands,landscape movies,landscapes,naturalistic stimuli,nature,neuroaesthetics,org,scene preference,value,video,www},
mendeley-tags = {aesthetics,fmri,landscapes,nature,neuroaesthetics,video},
month = {jul},
number = {July},
pages = {1--22},
title = {{From Visual Perception to Aesthetic Appeal: Brain Responses to Aesthetically Appealing Natural Landscape Movies}},
url = {https://www.frontiersin.org/articles/10.3389/fnhum.2021.676032/full},
volume = {15},
year = {2021}
}
@article{Isik2019,
abstract = {Visual aesthetic experiences unfold over time, yet most of our understanding of such experi- ences comes from experiments using static visual stimuli and measuring static responses. Here, we investigated the temporal dynamics of subjective aesthetic experience using tem- porally extended stimuli (movie clips) in combination with continuous behavioral ratings. Two groups of participants, a rate group (n = 25) and a viewgroup (n = 25), watched 30-sec- ond video clips of landscapes and dance performances in test and retest blocks. The rate group reported continuous ratings while watching the videos, with an overall aesthetic judg- ment at the end of each video, in both test and retest blocks. The viewgroup, however, pas- sively watched the videos in the test block, reporting only an overall aesthetic judgment at the end of each clip. In the retest block, the viewgroup reported both continuous and overall judgments. When comparing the two groups, we found that the task of making continuous ratings did not influence overall ratings or agreement across participants. In addition, the degree of temporal variation in continuous ratings over time differed substantially by observer (from slower “integrators” to “fast responders”), but less so by video. Reliability of continuous ratings across repeated exposures was in general high, but also showed notable variance across participants. Together, these results show that temporally extended stimuli produce aesthetic experiences that are not the same from person to person, and that contin- uous behavioral ratings provide a reliable window into the temporal dynamics of such aes- thetic experiences while not materially altering the experiences themselves. Introduction},
author = {Isik, Ayse Ilkay and Vessel, Edward A},
doi = {10.1371/journal.pone.0223896},
editor = {Ferrer, Rodrigo},
file = {:Users/ilkayisik/Documents/Mendeley Desktop/Isik, Vessel - 2019 - Continuous ratings of movie watching reveal idiosyncratic dynamics of aesthetic enjoyment.pdf:pdf},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {aesthetics,behavioral,continuous ratings,visual},
mendeley-tags = {aesthetics,behavioral,continuous ratings,visual},
month = {oct},
number = {10},
pages = {e0223896},
title = {{Continuous ratings of movie watching reveal idiosyncratic dynamics of aesthetic enjoyment}},
url = {http://dx.plos.org/10.1371/journal.pone.0223896 https://dx.plos.org/10.1371/journal.pone.0223896},
volume = {14},
year = {2019}
}
